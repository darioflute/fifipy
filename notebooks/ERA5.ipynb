{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9b1b1b9-79ad-40c3-b07b-f72fc4f46fcf",
   "metadata": {},
   "source": [
    "# Requesting ERA 5 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dbf4c4-af66-4463-bf4c-395ad7cb7445",
   "metadata": {},
   "source": [
    "# Step 0\n",
    "## Istalling the codes\n",
    "\n",
    "The precipitated water vapor is computed as:\n",
    "\n",
    "$ PWV = \\frac{1}{\\rho_w g} \\int_{P_f}^0 q(P) dP $\n",
    "\n",
    "with $q(P)$ the specific humidity as function of the altitude pressure (g of water per Kg of air) at a pressure level, $\\rho_w = 1000$ kg/m$^3$ water density, and $g$ is the gravity acceleration.\n",
    "$q(P)$ is linearly interpolated along the flight path in the grid of longitude, latitude, and time.\n",
    "\n",
    "\n",
    "To retrieve the ERA 5 data, you need to install their API and open an account of CDS.\n",
    "First of all, create a conda environment for ERA5:\n",
    "\n",
    "```\n",
    "conda create -n ERA5\n",
    "conda activate ERA5\n",
    "```\n",
    "\n",
    "Then, install:\n",
    "\n",
    "```\n",
    "conda install cartopy\n",
    "conda install xarray\n",
    "```\n",
    "\n",
    "Then, install cdsapi, the ERA5 API (instructions at: https://cds.climate.copernicus.eu/api-how-to)\n",
    "\n",
    "```\n",
    "pip install cdsapi\n",
    "```\n",
    "\n",
    "Finally, open an account on CDS:\n",
    "\n",
    "https://cds.climate.copernicus.eu/user/register?destination=%2F%23!%2Fhome\n",
    "\n",
    "\n",
    "At this point, the routines to read the ERA5 data contained in the library fifipy can be installed:\n",
    "\n",
    "```\n",
    "git clone https://github.com/darioflute/fifipy.git\n",
    "pip install -e fifipy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea5e23-2c61-475c-a923-6c5bb47a8b40",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "## Get the flight path from data on the server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be91d34-b37d-4e55-9fab-6844f4503356",
   "metadata": {},
   "source": [
    "The following file can be copied into flightpath.py in the server and then imported.\n",
    "If the data are local, it can be imported from fifipy:\n",
    "\n",
    "```\n",
    "from fifipy import flightpath\n",
    "```\n",
    "\n",
    "and then used locally. Otherwise, one has to copy the following file into the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a658004e-c7b6-4665-a5e1-e8e645e0a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create flight path\n",
    "#!/usr/bin/env python\n",
    "def flightpath(path, flight, outpath='./'):\n",
    "    from glob import glob as gb\n",
    "    from astropy.io import fits\n",
    "    from astropy.time import Time\n",
    "    from astropy.table import Table\n",
    "    import numpy as np\n",
    "    import re\n",
    "    import os\n",
    "    \n",
    "    files = sorted(gb(path+'*lw.fits'))\n",
    "    bfiles = sorted(gb(path+'*sw.fits'))\n",
    "    \n",
    "    # Sort according to time\n",
    "    timefile = np.array([os.path.basename(file)[6:12] for file in files])\n",
    "    s = np.argsort(timefile)\n",
    "    files = np.array(files)\n",
    "    bfiles = np.array(bfiles)\n",
    "    files = files[s]\n",
    "    if len(bfiles) > 0:\n",
    "        bfiles = bfiles[s]\n",
    "\n",
    "    lon = []\n",
    "    lat = []\n",
    "    time = []\n",
    "    date = []\n",
    "    press = []\n",
    "    altitude = []\n",
    "    obj = []\n",
    "    obstype = []\n",
    "    za = []\n",
    "    restwav = []\n",
    "    brestwav = []\n",
    "    redshift = []\n",
    "    \n",
    "    obsdate_old = ''\n",
    "    for i, file in enumerate(files):\n",
    "        # Check if file is manual or has XX in the name\n",
    "        if re.match(r\".*_manual_.*\", file) or re.match(r\".*XX.*\", file):\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                with fits.open(file) as hdl:\n",
    "                    header = hdl['PRIMARY'].header\n",
    "                    lon.append(header['LON_STA'])\n",
    "                    lat.append(header['LAT_STA'])\n",
    "                    press.append(header['HIERARCH STATICAIRPRESS'])\n",
    "                    obsdate=header['DATE-OBS']\n",
    "                    obj.append(header['OBJECT'])\n",
    "                    obstype.append(header['OBSTYPE'])\n",
    "                    altitude.append(header['HIERARCH BAROALTITUDE'])\n",
    "                    za.append(header['ZA_START'])\n",
    "                    try:\n",
    "                        z = header['REDSHIFT']\n",
    "                    except:\n",
    "                        z = 0\n",
    "                    redshift.append(z)\n",
    "                    restw = header['RESTWAV']\n",
    "                    if restw < 0:\n",
    "                        restw = header['WAVECENT']\n",
    "                    restwav.append(restw)\n",
    "                    if obsdate[0:4] == '1970':\n",
    "                        print(file ,' has year 1970')\n",
    "                        if obsdate_old != '':\n",
    "                            seconds = int(obsdate_old[-2:])\n",
    "                            if seconds < 30:\n",
    "                                seconds += 30\n",
    "                            else:\n",
    "                                seconds = 59\n",
    "                            obsdate = '{0:s}{1:02d}'.format(obsdate_old[:-2], seconds)\n",
    "                        else:\n",
    "                            print('impossible to repair !')\n",
    "                    date.append(obsdate)\n",
    "                    unixt = Time(obsdate).unix\n",
    "                    time.append(unixt)\n",
    "                    obsdate_old = obsdate\n",
    "                if len(bfiles) > 0:\n",
    "                    with fits.open(bfiles[i]) as hdl:\n",
    "                        header = hdl['PRIMARY'].header\n",
    "                        restw = header['RESTWAV']\n",
    "                        if restw < 0:\n",
    "                            restw = header['WAVECENT']\n",
    "                        brestwav.append(restw)\n",
    "            except:\n",
    "                print(file, ' is corrupted')\n",
    "        \n",
    "    lon = np.array(lon)\n",
    "    lat = np.array(lat)\n",
    "    time = np.array(time)\n",
    "    press = np.array(press)\n",
    "    date = np.array(date)\n",
    "    obj = np.array(obj)\n",
    "    obstype = np.array(obstype)\n",
    "    altitude = np.array(altitude)\n",
    "    za = np.array(za)\n",
    "    restwav = np.array(restwav)\n",
    "    brestwav = np.array(brestwav)\n",
    "    redshift = np.array(redshift)\n",
    "\n",
    "    \n",
    "    # Sort with unixt\n",
    "    s = np.argsort(time)\n",
    "    lon = lon[s]\n",
    "    lat = lat[s]\n",
    "    time = time[s]\n",
    "    press = press[s]\n",
    "    date = date[s]\n",
    "    obj = obj[s]\n",
    "    obstype = obstype[s]\n",
    "    altitude = altitude[s]\n",
    "    za = za[s]\n",
    "    if len(bfiles) > 0:\n",
    "        brestwav = brestwav[s]\n",
    "    redshift = redshift[s]\n",
    "        \n",
    "    # Save in a fits file\n",
    "    outname = outpath+'/F'+str(flight)+'path.fits'\n",
    "    hdu = fits.PrimaryHDU()\n",
    "    hdu.header['Flight'] = flight\n",
    "    hdu.header['Time_sta'] = date[0]\n",
    "    hdu.header['Time_end'] = date[-1]\n",
    "    hdu1 = fits.ImageHDU()\n",
    "    hdu1.data = lon\n",
    "    hdu1.header['EXTNAME'] = 'Longitude'\n",
    "    hdu2 = fits.ImageHDU()\n",
    "    hdu2.data = lat\n",
    "    hdu2.header['EXTNAME'] = 'Latitude'\n",
    "    hdu3 = fits.ImageHDU()\n",
    "    hdu3.data = press\n",
    "    hdu3.header['EXTNAME'] = 'Pressure'\n",
    "    hdu4 = fits.ImageHDU()\n",
    "    hdu4.data = time\n",
    "    hdu4.header['EXTNAME'] = 'Time'\n",
    "    col1 = fits.Column(name='Object', format='20A', array=obj)\n",
    "    hdu5 = fits.BinTableHDU.from_columns([col1], name='Object')\n",
    "    col1 = fits.Column(name='Obstype', format='10A', array=obj)\n",
    "    hdu6 = fits.BinTableHDU.from_columns([col1], name='Obstype')\n",
    "    hdu7 = fits.ImageHDU()\n",
    "    hdu7.data = altitude\n",
    "    hdu7.header['EXTNAME'] = 'Altitude'\n",
    "    hdu8 = fits.ImageHDU()\n",
    "    hdu8.data = za\n",
    "    hdu8.header['EXTNAME'] = 'ZenithAngle'\n",
    "    hdu9 = fits.ImageHDU()\n",
    "    hdu9.data = redshift\n",
    "    hdu9.header['EXTNAME'] = 'Redshift'\n",
    "    hdu10 = fits.ImageHDU()\n",
    "    hdu10.data = restwav\n",
    "    hdu10.header['EXTNAME'] = 'RedRestWavelength'\n",
    "    if len(bfiles) > 0:\n",
    "        hdu11 = fits.ImageHDU()\n",
    "        hdu11.data = brestwav\n",
    "        hdu11.header['EXTNAME'] = 'BlueRestWavelength'\n",
    "        hdul = fits.HDUList([hdu, hdu1, hdu2, hdu3, hdu4, hdu5, hdu6, hdu7, hdu8, hdu9, hdu10, hdu11])\n",
    "    else:\n",
    "        hdul = fits.HDUList([hdu, hdu1, hdu2, hdu3, hdu4, hdu5, hdu6, hdu7, hdu8, hdu9, hdu10])\n",
    "    hdul.writeto(outname, overwrite=True)\n",
    "    hdul.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370136d6-1913-4fe6-b3a8-d0787d4a50b2",
   "metadata": {},
   "source": [
    "In the server, open an interactive Python session and write the following lines to\n",
    "retrieve the flight path for flights 803 and 804.\n",
    "\n",
    "```\n",
    "source ~/.bashrc\n",
    "ipython\n",
    "from flightpath import flightpath\n",
    "# December flights\n",
    "for f in range(803,805):\n",
    "    print(f)\n",
    "    path = '/persistent_front/missions/2021/*'+str(f)+'/raw/r0/data/si/F*'+str(f)+'*/Data/'\n",
    "    flightpath(path, f, 'outputdir')  \n",
    "```\n",
    "\n",
    "The flight path files will be saved in the directory outputdir.\n",
    "You can, at this point, transfer these files in you laptop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c1578-55c5-4017-96c6-ed4dc3c0babe",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "## Grab the data from ERA 5\n",
    "\n",
    "Once the flight path files are stored in a given path, the routine pwvFlight will do the queries to the ERA 5 database and retrieve the satellite data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01de57-be90-4b12-89a0-57d99ba522f5",
   "metadata": {},
   "source": [
    "from fifipy.era5 import pwvFlight\n",
    "\n",
    "flights = [845,846,847,848]\n",
    "for f in flights:\n",
    "    print(f)\n",
    "    pwvFlight(f, path='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac9a4d8-1a19-46e9-bf1e-077421bb2177",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "## Compute the PWV values for the SOFIA flight path\n",
    "\n",
    "At this point it is possible to create the PWV values for the flight path and append the estimates to the flight path files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573a9f8d-5054-4a6d-a3d0-92cfe2a88b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fifipy.era5 import addPWV\n",
    "\n",
    "flights = [845,846,847,848]\n",
    "for f in flights:\n",
    "    print(f)\n",
    "    addPWV(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b1575a-31a8-4f56-9f47-a80135d35549",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "## Rescale and give list of values\n",
    "\n",
    "The program addObsWVZ from fifipy can be used for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1095f93c-e24c-418e-80b1-814d87ee5b67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
